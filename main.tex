\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[a4paper, total={6in, 9in}]{geometry}

\usepackage{amsthm}
 
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\title{
    CS638 Chapter: \\
    Motion Planning with Probabilistic Guarantee
}
\author{
    Jatin Jindal, 160308\\
    \texttt{jatinj@iitk.ac.in}
    \and
    Sahil Dhull, 160607\\
    \texttt{sahild@iitk.ac.in}
    \and
    Vibhor Porwal, 160778\\
    \texttt{vibhorp@iitk.ac.in}
}
\date{March 2019}

\begin{document}

\maketitle

\section{Introduction}
\textbf{**Section names are temporary}

% ----------------------------------------------------------------
\section{Jatin's Part:}
\subsection{Motion planning and control from temporal logic specifications with probabilistic satisfaction guarantees}
\subsubsection{Objective:}

\subsubsection{Settings and Assumptions:}

\subsubsection{Content and Analysis:}

\subsubsection{Conclusion:}

\subsection{Negotiating the probabilistic satisfaction of temporal logic motion specifications}
\subsubsection{Objective:}

\subsubsection{Settings and Assumptions:}

\subsubsection{Content and Analysis:}

\subsubsection{Conclusion:}

\subsection{}
\subsubsection{Objective:}

\subsubsection{Settings and Assumptions:}

\subsubsection{Content and Analysis:}

\subsubsection{Conclusion:}

\subsection{}
\subsubsection{Objective:}

\subsubsection{Settings and Assumptions:}

\subsubsection{Content and Analysis:}

\subsubsection{Conclusion:}


% ----------------------------------------------------------------
\section{Sahil's Part:}
\subsection{Temporal logic control in dynamic environments with probabilistic satisfaction guarantees}
\subsubsection{Objective:}
To find a control strategy that maximizes the
probability of satisfying a specification given in Probabilistic
Computation Tree Logic (PCTL) under 3 different settings.
\subsubsection{Settings and Assumptions:}
The environment is dynamic, with a set of disjoint regions and some of them separated from each other by doors. Doors can opened or closed.
However, we assume that door transition occur in synchronisation with robot transitions.
\begin{enumerate}
    \item \textbf{Setting 1:}
        Assumption is that when a robot observes a door, it knows perfectly well if it is opened or closed. Moreover, robot knows a priori on the probability that each door is open or closed.
    \item \textbf{Setting 2:}
        Here the assumption on priori probability is removed. But 100\% sensing accuracy is still assumed.
    \item \textbf{Setting 3:}
        Here both assumptions are removed. However, another assumption is made i.e. success and failure rates of door observation are known and fixed (given in the form of probabilities).
\end{enumerate}
\subsubsection{Preliminaries:}
\theoremstyle{definition}
\begin{definition}{Markov Decision Process (MDP)} $\mathcal{M}$ is a tuple (S,$s_0$,Act,T,L), where S is a finite set of states, $s_0 \in$S is the start state, Act is finite set of actions, T:S\times Act\times S $\rightarrow$ [0,1] is transition probability function, L:S$\rightarrow 2^{AP}$ is the labelling function assigned to each s in S.
\end{definition}
\begin{definition}{Probabilistic Computation Tree Logic (PCTL)}\\
We will be only dealing with PCTL of form $P_{max=?}[\phi_1 \mathcal{U} \phi_2]$ which is the maximum probability for which there exists a policy $\pi$ such that the formula "$\phi_1$ until $\phi_2$" is satisfied.
\end{definition}
\begin{definition}{Mixed Observability Markov Decision Process (MOMDP)} \cite{sahil1}
is a tuple (S,$s_0$,X,$\Theta$,Act,T,O,L), where S is the set of fully observable states, $s_0$ is the initial fully observable state, X is the set of hidden states, $\Theta$ is finite set of observations, Act is a finite set of actions, T(s,x,$\alpha$,$s^'$) = P($s^{'}\mid$s,x,$\alpha$) is probability of making a transition to fully observable state $s^'$ if action $\alpha$ is applied in state s and hidden state is x, O($s^'$,$x^'$,$\alpha$,o) = P(o$\mid s^{'}$,$x^'$,$\alpha$) describe the probability of observing o from state s when hidden state is x after action $\alpha$, and L:S$\rightarrow 2^{AP}$ is the labelling function.
\end{definition}

\subsubsection{Content and Analysis:}
\begin{enumerate}
    \item \textbf{Setting 1:}\\
    \textbf{MDP Model construction:} \\
    
    \textbf{PCTL Control Synthesis:}\\
    Once the MDP is contructed, problem is solved by tool developed in \cite{jatin1}. Inputs are an MDP and a PCTL specification and output will be policy and maximum probability.
\end{enumerate}


\subsubsection{Conclusion:}

One of the key limitations of the proposed approaches is the assumption that the doors only change state in synchrony with the motion of the robot.

%       -------------------------------- 
\subsection{Probabilistic control from time-bounded temporal logic specifications in dynamic environments}
\subsubsection{Objective:}

\subsubsection{Settings and Assumptions:}

\subsubsection{Content and Analysis:}

\subsubsection{Conclusion:}


\\
%       -------------------------------- 
\subsection{Time-Bounded Reachability Probabilities in Continuous-Time Markov Decision Processes}
\subsubsection{Objective:}

\subsubsection{Settings and Assumptions:}

\subsubsection{Content and Analysis:}

\subsubsection{Conclusion:}

\\
%       -------------------------------- 
\subsection{Efficient
computation of time-bounded reachability probabilities in uniform
continuous-time Markov decision processes}
\subsubsection{Objective:}

\subsubsection{Settings and Assumptions:}

\subsubsection{Content and Analysis:}

\subsubsection{Conclusion:}


% ----------------------------------------------------------------
\section{Vibhor's Part:}
\subsection{ Incremental control synthesis in probabilistic environments with Temporal Logic constraints}
\subsubsection{Objective:}

\subsubsection{Settings and Assumptions:}

\subsubsection{Content and Analysis:}

\subsubsection{Conclusion:}



%  ---------------------------------------------------------------

\begin{thebibliography}{}
\bibitem{jatin1}
Morteza Lahijanian, Joseph Wasniewski, Sean B. Andersson, Calin Belta.
\texttt{"Motion planning and control from temporal logic specifications with probabilistic satisfaction guarantees"}
ICRA 2010: 3227-3232
\bibitem{jatin2}
Igor Cizelj, Calin Belta
\texttt{"Negotiating the probabilistic satisfaction of temporal logic motion specifications"}
IROS 2013: 4320-4325
\bibitem{jatin3}

\texttt{""}

\bibitem{jatin4}

\texttt{""}


% --------------------------------------------------------
\bibitem{sahil1}
I. Medina Ayala, Sean B. Andersson, Calin Belta.
\texttt{"Temporal logic control in dynamic environments with probabilistic satisfaction guarantees"}
IROS 2011: 3108-3113
\bibitem{sahil2}
I. Medina Ayala, Sean B. Andersson, Calin Belta.
\texttt{"Probabilistic control from time-bounded temporal logic specifications in dynamic environments"}
ICRA 2012: 4705-4710
\bibitem{sahil3}
M. R. NeuhauBer and L. Zhang.
\texttt{"Time-bounded reachability probabilities
in continuous-time Markov decision processes"}
In Quantitative Evaluation of Systems (QEST), IEEE CS Press, pp. 209–218, 2010.
\bibitem{sahil4}
C. Baier, H. Hermanns, J.-P. Katoen, and B. R. Haverkort.
\texttt{"Efficient computation of time-bounded reachability probabilities in uniform continuous-time Markov decision processes"}
Theor. Comp. Sci., vol. 345, no. 1, pp. 2–26, 2005.
% --------------------------------------------------------
\bibitem{vibhor1}
Alphan Ulusoy, Tichakorn Wongpiromsarn, Calin Belta.
\texttt{"Incremental control synthesis in probabilistic environments with Temporal Logic constraints"}

\bibitem{vibhor2}
\texttt{""}

\bibitem{vibhor3}
\texttt{""}


\end{thebibliography}

\end{document}
