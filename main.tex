\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[a4paper, total={6in, 9in}]{geometry}
\usepackage[options ]{algorithm2e}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsthm}
 \usepackage{amssymb}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\title{
    CS638 Chapter: \\
    Motion Planning with Probabilistic Guarantee
}
\author{
    Jatin Jindal, 160308\\
    \texttt{jatinj@iitk.ac.in}
    \and
    Sahil Dhull, 160607\\
    \texttt{sahild@iitk.ac.in}
    \and
    Vibhor Porwal, 160778\\
    \texttt{vibhorp@iitk.ac.in}
}
\date{March 2019}

\begin{document}

\maketitle

\section{Introduction}
\textbf{**Section names are temporary}

% ----------------------------------------------------------------
\section{Jatin's Part:}
\subsection{Motion planning and control from temporal logic specifications with probabilistic satisfaction guarantees}
\subsubsection{Objective:} 
\subsubsection{Settings and Assumptions:}

\subsubsection{Content and Analysis:}

\subsubsection{Conclusion:}

\subsection{Negotiating the probabilistic satisfaction of temporal logic motion specifications}
\subsubsection{Objective:} Given the motion specification of a robot in the form of PCTL(probabilistic computation tree logic) formula, the aim is to generate MDP control policies for different kind of PCTL formulas.


\subsubsection{Settings and Assumptions:} We consider a robot that moves in a partitioned environment by applying a given set of motion primitives allowing it to steer between
adjacent regions. Because of sensor and actuation noise, while applying an available motion primitive at a region, the robot can transit to more than one adjacent region. We assume that the probabilities of these transitions are known and the robot can determine its current region precisely.

\subsubsection{Content and Analysis:}

\subsubsection{Conclusion: } In this paper, we complete the effort that was started in [1]
and [2] and present the entire MDP control synthesis algorithm from PCTL formulas that include Boolean operators, tempo-ral operators, expected cost operators, and any combinations
thereof. We can also accommodate nested probabilities,

\subsection{Temporal Logic Motion Planning and Control With Probabilistic Satisfaction Guarantees}
\subsubsection{Objective:}

\subsubsection{Settings and Assumptions:}

\subsubsection{Content and Analysis:}

\subsubsection{Conclusion:}

\subsection{}
\subsubsection{Objective:}

\subsubsection{Settings and Assumptions:}

\subsubsection{Content and Analysis:}

\subsubsection{Conclusion:}


% ----------------------------------------------------------------
\section{Sahil's Part:}
\subsection{Temporal logic control in dynamic environments with probabilistic satisfaction guarantees}
\subsubsection{Objective:}
To find a control strategy that maximizes the
probability of satisfying a specification given in Probabilistic
Computation Tree Logic (PCTL) under 3 different settings in a dynamic environment.
\subsubsection{Settings and Assumptions:}
The environment is dynamic, with a set of disjoint regions and some of them separated from each other by doors. Doors can opened or closed.
However, we assume that door transition occur in synchronisation with robot transitions.
\begin{enumerate}
    \item \textbf{Setting 1:}
        Assumption is that when a robot observes a door, it knows perfectly well if it is opened or closed. Moreover, robot knows a priori on the probability that each door is open or closed.
    \item \textbf{Setting 2:}
        Here the assumption on priori probability is removed. But 100\% sensing accuracy is still assumed.
    \item \textbf{Setting 3:}
        Here both assumptions are removed. However, another assumption is made i.e. success and failure rates of door observation are known and fixed (given in the form of probabilities).
\end{enumerate}
\subsubsection{Preliminaries:}
\theoremstyle{definition}
\begin{definition}{Markov Decision Process (MDP)} $\mathcal{M}$ is a tuple (S,$s_0$,Act,T,$\Pi$,L,c), where S is a finite set of states, $s_0 \in$S is the start state, Act is finite set of actions, $T:S\times Act\times$ S $\rightarrow$ [0,1] is transition probability function, $\Pi$ is a finite set of atomic propositions, L:S$\rightarrow 2^{\Pi}$ is the labelling function assigned to each s in S, Cost(c): $S \times Act \rightarrow \mathbb{R}^{\geq 0}$
\end{definition}

\begin{definition}{Syntax of PCTL:}\\
$\phi ::= true\:\: |\:\: \pi \:\:|\:\: \neg \phi \:\:|\:\: \phi \wedge \phi \:\:|\:\: P_{\Join p}[\psi] \:\:|\:\: \varepsilon_{\Join c}[\phi]$ \hfill state formulas\\
$\psi ::= X\phi \:\: |\:\: \phi\: \mathcal{U}^{\le k}\phi \:\: | \:\: \phi\: \mathcal{U} \phi $ \hfill path formulas\\

$\Join \in \{\le, <, \geq, >\}; p \in [0, 1], c \in [0, \infty]$ and $k \in \mathbb{N}$
\end{definition}


\begin{definition}{Semantics of PCTL:}
For any state $s \in S$, the satisfaction relation $\models$ is defined inductively as follows:\\
(1) s $\models$ true for all $s \in S$;\\
(2) s $\models \pi \Leftrightarrow \pi \in L(q)$;\\
(3) s $\models (\phi_1 \wedge \phi_2) \Leftrightarrow s \models \phi_1 \wedge s \models \phi_2$;\\
(4) $s \models \neg \phi \Leftrightarrow s \not \models \phi$;\\
(5) $s \models P_{\Join p}[\psi] \Leftrightarrow p_\mu^s \Join p;$\\
(6) $s \models \varepsilon_{\Join c}[\phi] \Leftrightarrow e_\mu^s \Join c;$\\

$p_\mu^s$ is the probability of all the infinite paths that start from s and satisfy $\psi$ under policy $\mu$ and $e_\mu^s(\phi)$ denotes the total expected cost of reaching a state that satisfy $\phi$ from s under $\mu$. Moreover, for any path $\omega \in $Path.\\
(1) $\omega \models X \phi \Leftrightarrow w(1) \Leftrightarrow \phi$\\
(2) $\omega \models \phi_1 \mathcal{U}^{\le k} \phi_2 \Leftrightarrow \exists i \le k, \omega(i) \models \phi_2 \wedge w(j) \models \phi_1 \forall j < i$;\\
(3) $\omega \models \phi_1 \mathcal{U} \phi_2 \Leftrightarrow \exists \ge 0, \omega \models \phi_1 \mathcal{U}^{\le k} \phi_2$
\end{definition}
\begin{definition}{Probabilistic Computation Tree Logic (PCTL)}\\
We will be only dealing with PCTL of form $P_{max=?}[\phi_1 \mathcal{U} \phi_2]$ which is the maximum probability for which there exists a policy $\pi$ such that the formula "$\phi_1$ until $\phi_2$" is satisfied.
\end{definition}
\begin{definition}{Mixed Observability Markov Decision Process (MOMDP)} \cite{sahil1}
is a tuple (S,$s_0$,X,$\Theta$,Act,T,O,L), where S is the set of fully observable states, $s_0$ is the initial fully observable state, X is the set of hidden states, $\Theta$ is finite set of observations, Act is a finite set of actions, T(s,x,$\alpha$,$s^{'}$) = P($s^{'}\mid$s,x,$\alpha$) is probability of making a transition to fully observable state $s^{'}$ if action $\alpha$ is applied in state s and hidden state is x, O($s^{'}$,$x^{'}$,$\alpha$,o) = P(o$\mid s^{'}$,$x^{'}$,$\alpha$) describe the probability of observing o from state s when hidden state is x after action $\alpha$, and L:S$\rightarrow 2^{AP}$ is the labelling function.
\end{definition}

\subsubsection{Content and Analysis:}
\begin{enumerate}
    \item \textbf{Setting 1:}
    \begin{itemize}
        \item MDP Model construction: \\
        $\mathcal{M}$ = (S,$s_0$,Act,T,L).\\
        S is the set of all regions.\\
        S = $R_1\cup \bigcup_{r\in R_2} \{(r,0),(r,1)\}$ where $R_1$ is the regions having no door and $R_2$ is set of regions having door.\\
        Act is set of actions which are motion primitives available at each region/state.\\
        Assumption: Transition Probability is only dependant on current region.\\
        Hence T(s,$\alpha$,$s^{'}$) = P($s^{'}\mid$s,$\alpha$).\\
        L is the labelling function assigning properties to various regions, which are used in PCTL specification formation.
        \item PCTL Control Synthesis:\\
        Once the MDP is contructed, problem is solved by tool developed in \cite{jatin1} as discussed in section 2.1. Inputs are an MDP and a PCTL specification and output will be policy and maximum probability.
    \end{itemize}
    \item \textbf{Setting 2:}
    \begin{itemize}
        \item MOMDP Model construction:
        Tuple (S,$s_0$,X,$\Theta$,Act,T,O,L)\\
        S = R (set of regions)\\
        X = $\bigcup_{b_i\in B} b_i$ where is $b_i$ is boolean denoting state of each door i.e. $b_i$ = 1 means door is closed and $b_i$ = 0 means door is open.\\
        $\Theta$ = $\{ open, closed \}$ denoting states of door.\\
        Act is the set of primitives available at the state/region.\\
        T(s,x,$\alpha$,$s^{'}$) = P($s^{'}\mid$s,$\alpha$) for the regions without door.\\
        For the regions with door,
        \[ T(s,x,\alpha,s^{'}) = \sum_{s\in S} P(s^{'}\mid s,\alpha) P(o \mid s^{'},x^{'},\alpha) \]
        Since we have perfect sensing, $P(o \mid s^{'},x^{'},\alpha)$ = 1 if o is open and 0 if o is closed.\\
        O($o, s^{'},x^{'},\alpha$) = $P(o \mid s^{'},x^{'},\alpha)$ = 0 or 1\\
        L is the labelling function assigning properties to various regions over which PCTL specification is defined.
        \item PCTL Control Synthesis:\\
        We only know the state of current door, so we assume all other doors are open. This leaves us with n+1 configurations, where n is the number of doors. For each configuration, MDP is constructed, and optimal policy is obtained. Let $\Pi$ denote set of policies for all configurations/scenarios with $pi_0$ being scenario in which all doors are open.\\
        We partition S into $S^{yes}$ (states satisfying PCTL formula with probability 1), $S^{no}$ (states satisfying PCTL formula with probability 0) and $S^{?}$ (remaining states).\\
        Now while running, robot chooses the policy dynamically from $\Pi$ based on its current configuration (e.g. if it enters a region containing door and door is closed, it will choose corresponding $\pi_i$), applies that policy to obtain new state, until the state is in either $S^{yes}$ or $S^{no}$. The algorithm is given below with line 10 removed (line 10 is for setting 3).\\
    \end{itemize}
    \item \textbf{Setting 3:}
    \begin{itemize}
        \item MOMDP Model construction:\\
        Here, uncertainity in robot's sensor is also considered.
        Only the transition probabilities for the regions containing a door change as per the following equation,
        \[ T(s,x,\alpha,s^{'}) = \sum_{s\in S} P(s^{'}\mid s,\alpha) P(o \mid s^{'},x^{'},\alpha) \]
        Now, $P(o \mid s^{'},x^{'},\alpha)$ will not be directly 0 or 1 depending on state of door, but we also incorporate some error/inaccuracy.
        \item PCTL Control Synthesis:\\
        $\Pi$ is calculated offline similar to last setting. When a region having a door is encountered, robot can either keep applying same policy or execute a new policy. The policy selected corresponds to the scenario that is most likely based on observation and given by following one-step lookahead,
        \[ p_s = \max_{\pi\in\Pi} \{ \sum_{s^{'}\in S^{?}} T(s,x,\pi,s^{'})\cdot p_{s^{'}}  + \sum_{s^{'}\in S^{yes}} T(s,x,\pi,s^{'})  \} \ \ \ --> SOLVE  \]
        \begin{algorithm}
        \caption{Setting 2 and 3 Online Algorithm \cite{sahil1}}\label{euclid}
        \begin{algorithmic}[1]
        \REQUIRE Set $\Pi$ = $\{ \pi_0,\pi_1,...,\pi_N \}$
        \STATE $\pi_*$ = $\pi_0$
        \STATE Act(s) $\leftarrow$ $\pi_*$(s)
        \STATE $s^{'}$ = execute Act(s)
        \STATE s = $s^{'}$
        \WHILE{True}
        \IF{s$\in S^{yes} \vee s \in S^{no}$}
        \STATE \textbf{break}
        \ELSE
        \IF{P(closed$\mid s^{'},b_i$,Act(s))=1}
        \STATE $\pi_i$ = \texttt{SOLVE}
        \STATE $\pi_*$ = $\pi_i$
        \ENDIF
        \STATE \textbf{goto} 2
        \ENDIF
        \ENDWHILE
        \end{algorithmic}
        \end{algorithm}
    \end{itemize}
\end{enumerate}


\subsubsection{Conclusion:}
Simulations have been performed by the researchers in the paper \cite{sahil1} and the results are similar to expectations in all the 3 settings.\\
Hence a solution to automatic deployment of robot in dynamic environment, provided a temporal logic specification to be satisfied, is presented in the paper assuming different levels of knowledge.\\
However, one of the key limitations of the proposed approaches is the assumption that the doors only change state in synchrony with the motion of the robot.

%       -------------------------------- 
\subsection{Probabilistic Control from Time-bounded Temporal Logic Specifications in Dynamic Environments}
\subsubsection{Objective:}
To find a control strategy for real time robotic system that satisfies Continuous Stochastic Logic (CSL) temporal logic specification, in a dynamic environment within a given time bound.

\subsubsection{Settings and Assumptions:}
We assume that robot can determine its current region accurately and motion primitives, that it is programmed with, allow it to move from one region to another provided the path is not blocked by closed door. Moreover, robot knows about state of door only when it is in a region adjacent to door.\\
And to account for noisy actuators, it is taken into account that if robot is to move to a region, it may actually move to some other adjacent region.\\
Change in state of door is assumed to follow poisson distribution, so the time between 2 subsequent switching events are exponential random variables.


\subsubsection{Content and Analysis:}

\subsubsection{Conclusion:}


\\
%       -------------------------------- 
\subsection{Time-Bounded Reachability Probabilities in Continuous-Time Markov Decision Processes}
\subsubsection{Objective:}

\subsubsection{Settings and Assumptions:}

\subsubsection{Content and Analysis:}

\subsubsection{Conclusion:}

\\
%       -------------------------------- 
\subsection{Efficient
computation of time-bounded reachability probabilities in uniform
continuous-time Markov decision processes}
\subsubsection{Objective:}

\subsubsection{Settings and Assumptions:}

\subsubsection{Content and Analysis:}

\subsubsection{Conclusion:}


% ----------------------------------------------------------------
\section{Vibhor's Part:}
\subsection{ Incremental control synthesis in probabilistic environments with Temporal Logic constraints}
\subsubsection{Objective:}

\subsubsection{Settings and Assumptions:}

\subsubsection{Content and Analysis:}

\subsubsection{Conclusion:}



%  ---------------------------------------------------------------

\begin{thebibliography}{}
\bibitem{jatin1}
Morteza Lahijanian, Joseph Wasniewski, Sean B. Andersson, Calin Belta.
\texttt{"Motion planning and control from temporal logic specifications with probabilistic satisfaction guarantees"}
ICRA 2010: 3227-3232
\bibitem{jatin2}
Igor Cizelj, Calin Belta
\texttt{"Negotiating the probabilistic satisfaction of temporal logic motion specifications"}
IROS 2013: 4320-4325
\bibitem{jatin3}

\texttt{""}

\bibitem{jatin4}

\texttt{""}


% --------------------------------------------------------
\bibitem{sahil1}
I. Medina Ayala, Sean B. Andersson, Calin Belta.
\texttt{"Temporal logic control in dynamic environments with probabilistic satisfaction guarantees"}
IROS 2011: 3108-3113
\bibitem{sahil2}
I. Medina Ayala, Sean B. Andersson, Calin Belta.
\texttt{"Probabilistic control from time-bounded temporal logic specifications in dynamic environments"}
ICRA 2012: 4705-4710
\bibitem{sahil3}
M. R. NeuhauBer and L. Zhang.
\texttt{"Time-bounded reachability probabilities
in continuous-time Markov decision processes"}
In Quantitative Evaluation of Systems (QEST), IEEE CS Press, pp. 209–218, 2010.
\bibitem{sahil4}
C. Baier, H. Hermanns, J.-P. Katoen, and B. R. Haverkort.
\texttt{"Efficient computation of time-bounded reachability probabilities in uniform continuous-time Markov decision processes"}
Theor. Comp. Sci., vol. 345, no. 1, pp. 2–26, 2005.
% --------------------------------------------------------
\bibitem{vibhor1}
Alphan Ulusoy, Tichakorn Wongpiromsarn, Calin Belta.
\texttt{"Incremental control synthesis in probabilistic environments with Temporal Logic constraints"}

\bibitem{vibhor2}
\texttt{""}

\bibitem{vibhor3}
\texttt{""}


\end{thebibliography}

\end{document}
